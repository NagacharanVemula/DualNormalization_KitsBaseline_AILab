  0%|                                         | 0/366 [00:00<?, ?it/s]  0%|                               | 1/366 [00:54<5:30:00, 54.25s/it]  1%|â–                            | 2/366 [06:47<23:16:18, 230.16s/it]  1%|â–                            | 3/366 [08:20<16:52:46, 167.40s/it]  1%|â–Ž                            | 4/366 [08:41<11:02:36, 109.83s/it]  1%|â–                            | 5/366 [10:07<10:08:27, 101.13s/it]  2%|â–                            | 6/366 [11:45<10:00:48, 100.14s/it]  2%|â–Œ                            | 7/366 [15:11<13:25:35, 134.64s/it]  2%|â–‹                            | 8/366 [21:04<20:18:00, 204.14s/it]  2%|â–‹                            | 9/366 [22:09<15:55:58, 160.67s/it]  3%|â–Š                           | 10/366 [25:38<17:21:12, 175.49s/it]  3%|â–Š                           | 11/366 [29:01<18:08:58, 184.05s/it]  3%|â–‰                           | 12/366 [30:23<15:02:21, 152.94s/it]  4%|â–‰                           | 13/366 [31:38<12:41:35, 129.45s/it]  4%|â–ˆ                            | 14/366 [32:12<9:49:26, 100.47s/it]  4%|â–ˆâ–                            | 15/366 [33:35<9:17:35, 95.32s/it]  4%|â–ˆâ–Ž                            | 16/366 [35:11<9:17:31, 95.58s/it]  5%|â–ˆâ–                            | 17/366 [36:17<8:23:55, 86.63s/it]  5%|â–ˆâ–                            | 18/366 [37:25<7:49:07, 80.88s/it]  5%|â–ˆâ–Œ                            | 19/366 [38:13<6:50:49, 71.03s/it]  5%|â–ˆâ–‹                            | 20/366 [38:38<5:30:11, 57.26s/it]  6%|â–ˆâ–‹                            | 21/366 [39:41<5:38:49, 58.93s/it]  6%|â–ˆâ–Š                            | 22/366 [40:05<4:37:47, 48.45s/it]  6%|â–ˆâ–‰                            | 23/366 [42:41<7:42:41, 80.94s/it]  7%|â–ˆâ–‰                            | 24/366 [44:27<8:22:51, 88.22s/it]  7%|â–ˆâ–ˆ                            | 25/366 [45:08<7:01:45, 74.21s/it]  7%|â–ˆâ–ˆâ–                           | 26/366 [45:45<5:56:11, 62.86s/it]  7%|â–ˆâ–ˆâ–                           | 27/366 [46:34<5:33:09, 58.97s/it]  8%|â–ˆâ–ˆâ–Ž                           | 28/366 [47:50<6:00:16, 63.96s/it]  8%|â–ˆâ–ˆâ–                           | 29/366 [48:09<4:43:40, 50.51s/it]  8%|â–ˆâ–ˆâ–                           | 30/366 [49:08<4:56:25, 52.93s/it]  8%|â–ˆâ–ˆâ–Œ                           | 31/366 [50:47<6:13:11, 66.84s/it]  9%|â–ˆâ–ˆâ–Œ                           | 32/366 [51:17<5:11:03, 55.88s/it]  9%|â–ˆâ–ˆâ–‹                           | 33/366 [52:13<5:09:50, 55.83s/it]  9%|â–ˆâ–ˆâ–Š                           | 34/366 [53:38<5:57:42, 64.65s/it] 10%|â–ˆâ–ˆâ–Š                           | 35/366 [54:27<5:30:28, 59.91s/it] 10%|â–ˆâ–ˆâ–‰                           | 36/366 [55:17<5:12:48, 56.88s/it] 10%|â–ˆâ–ˆâ–ˆ                           | 37/366 [56:54<6:18:08, 68.96s/it] 10%|â–ˆâ–ˆâ–ˆ                           | 38/366 [58:24<6:50:58, 75.18s/it] 11%|â–ˆâ–ˆâ–ˆâ–                          | 39/366 [58:57<5:41:55, 62.74s/it] 11%|â–ˆâ–ˆâ–ˆâ–Ž                          | 40/366 [59:25<4:42:43, 52.04s/it] 11%|â–ˆâ–ˆâ–‰                       | 41/366 [1:03:38<10:09:56, 112.60s/it] 11%|â–ˆâ–ˆâ–‰                       | 42/366 [1:09:19<16:17:19, 180.99s/it] 12%|â–ˆâ–ˆâ–ˆ                       | 43/366 [1:10:09<12:42:14, 141.59s/it] 12%|â–ˆâ–ˆâ–ˆâ–                      | 44/366 [1:11:11<10:32:18, 117.82s/it] 12%|â–ˆâ–ˆâ–ˆâ–                      | 45/366 [1:13:50<11:36:49, 130.25s/it] 13%|â–ˆâ–ˆâ–ˆâ–                       | 46/366 [1:14:43<9:30:30, 106.97s/it] 13%|â–ˆâ–ˆâ–ˆâ–Œ                        | 47/366 [1:15:42<8:11:42, 92.48s/it] 13%|â–ˆâ–ˆâ–ˆâ–‹                        | 48/366 [1:16:18<6:40:42, 75.61s/it] 13%|â–ˆâ–ˆâ–ˆâ–‹                        | 49/366 [1:17:11<6:03:02, 68.71s/it] 14%|â–ˆâ–ˆâ–ˆâ–Š                        | 50/366 [1:18:21<6:05:19, 69.37s/it] 14%|â–ˆâ–ˆâ–ˆâ–‰                        | 51/366 [1:19:35<6:10:07, 70.50s/it] 14%|â–ˆâ–ˆâ–ˆâ–‹                      | 52/366 [1:27:53<17:21:21, 198.99s/it] 14%|â–ˆâ–ˆâ–ˆâ–Š                      | 53/366 [1:28:43<13:24:59, 154.31s/it] 15%|â–ˆâ–ˆâ–ˆâ–Š                      | 54/366 [1:30:20<11:52:34, 137.03s/it] 15%|â–ˆâ–ˆâ–ˆâ–ˆ                       | 55/366 [1:31:09<9:32:38, 110.48s/it] 15%|â–ˆâ–ˆâ–ˆâ–‰                      | 56/366 [1:35:25<13:16:58, 154.25s/it] 16%|â–ˆâ–ˆâ–ˆâ–ˆ                      | 57/366 [1:36:09<10:24:02, 121.17s/it] 16%|â–ˆâ–ˆâ–ˆâ–ˆ                      | 58/366 [1:40:53<14:32:57, 170.06s/it] 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–                     | 59/366 [1:46:20<18:30:14, 216.98s/it] 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 60/366 [1:52:00<21:36:00, 254.12s/it] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 61/366 [1:52:28<15:47:03, 186.31s/it] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–                     | 62/366 [1:52:54<11:39:26, 138.05s/it] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 63/366 [1:53:49<9:31:59, 113.26s/it] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 64/366 [1:54:15<7:18:10, 87.06s/it] 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 65/366 [1:54:47<5:53:23, 70.44s/it] 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 66/366 [1:59:17<10:51:50, 130.37s/it] 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 67/366 [2:00:08<8:51:19, 106.62s/it] 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 68/366 [2:01:37<8:23:06, 101.30s/it] 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 69/366 [2:04:11<9:39:10, 117.01s/it] 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 70/366 [2:06:00<9:26:12, 114.77s/it] 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 71/366 [2:07:08<8:14:34, 100.59s/it] 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 72/366 [2:07:58<6:58:25, 85.39s/it] 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 73/366 [2:13:57<13:38:19, 167.58s/it] 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 74/366 [2:14:53<10:52:47, 134.13s/it] 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 75/366 [2:15:47<8:54:02, 110.11s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 76/366 [2:16:58<7:55:29, 98.38s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 77/366 [2:17:24<6:08:25, 76.49s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 78/366 [2:23:28<13:01:20, 162.78s/it] 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 79/366 [2:25:59<12:42:28, 159.40s/it] 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 80/366 [2:26:22<9:23:30, 118.22s/it] 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 81/366 [2:30:46<12:49:54, 162.09s/it] 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 82/366 [2:32:35<11:31:28, 146.09s/it] 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 83/366 [2:33:03<8:42:03, 110.68s/it] 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 84/366 [2:35:06<8:58:20, 114.54s/it] 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 85/366 [2:35:42<7:06:11, 91.00s/it] 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 86/366 [2:36:28<6:00:32, 77.26s/it] 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 87/366 [2:37:31<5:39:57, 73.11s/it] 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 88/366 [2:38:35<5:25:49, 70.32s/it] 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 89/366 [2:39:30<5:03:54, 65.83s/it] 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 90/366 [2:41:48<6:42:13, 87.44s/it] 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 91/366 [2:43:54<7:33:31, 98.95s/it] 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 92/366 [2:44:24<5:57:19, 78.25s/it] 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 93/366 [2:45:14<5:17:02, 69.68s/it] 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 94/366 [2:46:02<4:47:07, 63.34s/it] 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 95/366 [2:47:20<5:06:23, 67.84s/it] 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 96/366 [2:48:26<5:01:49, 67.07s/it] 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 97/366 [2:49:23<4:47:18, 64.08s/it] 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 98/366 [2:49:46<3:51:42, 51.88s/it] 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 99/366 [2:50:45<3:59:44, 53.87s/it] 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 100/366 [2:51:27<3:43:07, 50.33s/it] 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 101/366 [2:57:13<10:14:46, 139.20s/it] 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 102/366 [2:57:36<7:38:47, 104.27s/it] 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 103/366 [2:58:03<5:55:55, 81.20s/it] 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 104/366 [3:02:15<9:37:08, 132.17s/it] 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 105/366 [3:03:17<8:03:27, 111.14s/it] 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 106/366 [3:03:42<6:09:40, 85.31s/it] 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 107/366 [3:09:40<12:01:24, 167.12s/it] 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 108/366 [3:10:44<9:46:25, 136.38s/it] 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 109/366 [3:11:40<8:01:03, 112.31s/it] 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 110/366 [3:12:06<6:07:50, 86.21s/it] 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 111/366 [3:12:44<5:04:54, 71.74s/it] 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 112/366 [3:13:25<4:24:38, 62.51s/it] 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 113/366 [3:16:41<7:12:17, 102.52s/it] 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 114/366 [3:17:46<6:24:03, 91.44s/it] 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 115/366 [3:18:21<5:10:57, 74.33s/it] 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 116/366 [3:19:48<5:25:24, 78.10s/it] 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 117/366 [3:20:39<4:50:59, 70.12s/it] 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 118/366 [3:21:50<4:51:10, 70.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 119/366 [3:22:28<4:10:14, 60.79s/it] 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 120/366 [3:23:45<4:28:26, 65.47s/it] 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 121/366 [3:24:11<3:39:18, 53.71s/it] 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 122/366 [3:26:59<5:57:42, 87.96s/it] 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 123/366 [3:27:51<5:12:48, 77.24s/it] 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 124/366 [3:30:05<6:20:15, 94.28s/it] 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 125/366 [3:30:53<5:22:42, 80.34s/it] 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 126/366 [3:31:34<4:33:52, 68.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 127/366 [3:35:50<8:17:10, 124.81s/it] 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 128/366 [3:37:38<7:54:59, 119.75s/it] 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 129/366 [3:38:25<6:26:41, 97.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 130/366 [3:39:14<5:26:52, 83.10s/it] 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 131/366 [3:40:05<4:48:04, 73.55s/it] 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 132/366 [3:40:58<4:23:19, 67.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 133/366 [3:42:55<5:19:51, 82.37s/it] 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 134/366 [3:44:29<5:31:29, 85.73s/it] 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 135/366 [3:45:20<4:49:33, 75.21s/it] 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 136/366 [3:47:09<5:27:18, 85.38s/it] 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 137/366 [3:48:00<4:46:25, 75.05s/it] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 138/366 [3:50:52<6:35:35, 104.10s/it] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 139/366 [3:51:19<5:06:33, 81.03s/it] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 140/366 [3:52:14<4:35:43, 73.20s/it] 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 141/366 [3:53:09<4:14:52, 67.97s/it] 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 142/366 [3:54:05<3:59:45, 64.22s/it] 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 143/366 [3:54:35<3:21:09, 54.12s/it] 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 144/366 [3:55:32<3:22:58, 54.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 145/366 [4:00:06<7:24:08, 120.58s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 146/366 [4:00:54<6:02:13, 98.79s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 147/366 [4:01:21<4:42:28, 77.39s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 148/366 [4:02:59<5:03:20, 83.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 149/366 [4:03:51<4:28:05, 74.13s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 150/366 [4:04:45<4:04:59, 68.05s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 151/366 [4:05:08<3:15:37, 54.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 152/366 [4:05:57<3:08:21, 52.81s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 153/366 [4:06:59<3:17:10, 55.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 154/366 [4:08:00<3:22:18, 57.26s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 155/366 [4:08:58<3:22:14, 57.51s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 156/366 [4:09:58<3:23:45, 58.22s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 157/366 [4:15:40<8:19:30, 143.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 158/366 [4:19:48<10:05:03, 174.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 159/366 [4:26:29<13:57:30, 242.76s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 160/366 [4:27:04<10:19:02, 180.30s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 161/366 [4:30:00<10:11:59, 179.12s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 162/366 [4:30:43<7:49:37, 138.13s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 163/366 [4:31:38<6:22:37, 113.09s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 164/366 [4:32:39<5:28:23, 97.54s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 165/366 [4:33:19<4:29:15, 80.38s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 166/366 [4:35:42<5:30:18, 99.09s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 167/366 [4:36:37<4:44:52, 85.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 168/366 [4:37:20<4:01:08, 73.07s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 169/366 [4:41:05<6:29:25, 118.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 170/366 [4:42:29<5:53:18, 108.16s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 171/366 [4:43:42<5:17:47, 97.78s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 172/366 [4:44:39<4:35:51, 85.32s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 173/366 [4:45:32<4:03:15, 75.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 174/366 [4:51:49<8:51:33, 166.11s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 175/366 [4:53:41<7:56:47, 149.78s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 176/366 [4:54:43<6:31:06, 123.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 177/366 [4:55:44<5:29:59, 104.76s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 178/366 [4:56:39<4:41:46, 89.93s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 179/366 [4:57:24<3:57:45, 76.29s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 180/366 [4:58:39<3:55:26, 75.95s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 181/366 [5:00:10<4:08:19, 80.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 182/366 [5:00:39<3:19:59, 65.21s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 183/366 [5:01:18<2:54:06, 57.09s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 184/366 [5:01:56<2:36:10, 51.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 185/366 [5:07:27<6:48:27, 135.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 186/366 [5:08:14<5:26:06, 108.70s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 187/366 [5:08:39<4:10:09, 83.85s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 188/366 [5:09:33<3:42:02, 74.85s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 189/366 [5:11:19<4:07:45, 83.99s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 190/366 [5:12:00<3:28:40, 71.14s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 191/366 [5:17:52<7:33:17, 155.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 192/366 [5:18:42<5:58:49, 123.74s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 193/366 [5:19:47<5:06:34, 106.33s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 194/366 [5:21:41<5:10:43, 108.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 195/366 [5:22:08<3:59:28, 84.03s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 196/366 [5:22:39<3:12:56, 68.10s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 197/366 [5:23:49<3:14:06, 68.91s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 198/366 [5:24:44<3:00:52, 64.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 199/366 [5:25:19<2:35:26, 55.85s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 200/366 [5:26:32<2:48:10, 60.78s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 201/366 [5:31:43<6:13:28, 135.81s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 202/366 [5:32:29<4:58:00, 109.03s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 203/366 [5:33:07<3:58:28, 87.78s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 204/366 [5:33:35<3:08:39, 69.87s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 205/366 [5:34:24<2:50:12, 63.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 206/366 [5:35:32<2:52:50, 64.81s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 207/366 [5:36:52<3:04:03, 69.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 208/366 [5:37:30<2:38:06, 60.04s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 209/366 [5:43:09<6:15:52, 143.65s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 210/366 [5:44:06<5:05:58, 117.68s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 211/366 [5:45:04<4:17:39, 99.74s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 212/366 [5:45:54<3:38:02, 84.95s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 213/366 [5:47:20<3:37:13, 85.19s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 214/366 [5:48:52<3:40:39, 87.10s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 215/366 [5:49:35<3:06:25, 74.08s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 216/366 [5:50:01<2:29:04, 59.63s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 217/366 [5:51:41<2:58:09, 71.74s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 218/366 [5:54:21<4:01:55, 98.08s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 219/366 [6:01:10<7:48:52, 191.38s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 220/366 [6:03:40<7:15:26, 178.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 221/366 [6:04:15<5:27:58, 135.71s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 222/366 [6:05:04<4:23:43, 109.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 223/366 [6:06:17<3:55:35, 98.85s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 224/366 [6:07:22<3:29:23, 88.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 225/366 [6:13:33<6:47:40, 173.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 226/366 [6:15:50<6:18:37, 162.27s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 227/366 [6:18:35<6:17:59, 163.16s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 228/366 [6:22:50<7:18:37, 190.70s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 229/366 [6:24:58<6:32:23, 171.85s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 230/366 [6:25:52<5:09:26, 136.52s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 231/366 [6:26:22<3:55:16, 104.56s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 232/366 [6:27:52<3:43:37, 100.13s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 233/366 [6:29:14<3:30:13, 94.84s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 234/366 [6:30:44<3:25:18, 93.32s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 235/366 [6:34:09<4:37:21, 127.04s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 236/366 [6:35:02<3:46:36, 104.59s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 237/366 [6:40:09<5:55:40, 165.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 238/366 [6:41:06<4:43:21, 132.82s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 239/366 [6:41:33<3:33:53, 101.05s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 240/366 [6:43:02<3:24:31, 97.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 241/366 [6:44:18<3:10:03, 91.23s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 242/366 [6:44:59<2:36:53, 75.92s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 243/366 [6:45:29<2:07:31, 62.20s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 244/366 [6:46:07<1:51:34, 54.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 245/366 [6:47:04<1:52:18, 55.69s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 246/366 [6:48:00<1:51:08, 55.57s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 247/366 [6:49:41<2:17:22, 69.26s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 248/366 [6:50:31<2:05:16, 63.70s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 249/366 [6:52:12<2:26:00, 74.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 250/366 [6:53:28<2:25:06, 75.06s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 251/366 [6:54:16<2:08:25, 67.00s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 252/366 [6:54:51<1:48:54, 57.32s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 253/366 [7:01:16<4:52:59, 155.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 254/366 [7:05:57<6:00:59, 193.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 255/366 [7:06:18<4:21:49, 141.53s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 256/366 [7:07:10<3:30:27, 114.80s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 257/366 [7:08:52<3:21:24, 110.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 258/366 [7:13:31<4:50:36, 161.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 259/366 [7:14:52<4:04:45, 137.25s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 260/366 [7:15:50<3:20:23, 113.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 261/366 [7:17:00<2:55:33, 100.32s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 262/366 [7:23:28<5:23:23, 186.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 263/366 [7:30:04<7:08:26, 249.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 264/366 [7:30:54<5:22:39, 189.80s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 265/366 [7:32:17<4:25:12, 157.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 266/366 [7:38:50<6:20:38, 228.39s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 267/366 [7:39:14<4:35:12, 166.79s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 268/366 [7:40:33<3:49:48, 140.70s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 269/366 [7:41:35<3:09:05, 116.97s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 270/366 [7:42:47<2:45:37, 103.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 271/366 [7:45:01<2:58:32, 112.77s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 272/366 [7:48:22<3:37:51, 139.06s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 273/366 [7:49:31<3:02:56, 118.03s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 274/366 [7:50:19<2:28:39, 96.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 275/366 [7:51:02<2:02:39, 80.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 276/366 [7:52:59<2:17:36, 91.74s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 277/366 [7:53:16<1:42:36, 69.18s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 278/366 [7:54:08<1:33:54, 64.03s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 279/366 [7:55:03<1:28:55, 61.33s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 280/366 [7:56:03<1:27:37, 61.14s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 281/366 [7:56:46<1:18:43, 55.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 282/366 [7:57:57<1:24:16, 60.19s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 283/366 [8:01:16<2:21:07, 102.01s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 284/366 [8:01:39<1:47:01, 78.31s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 285/366 [8:02:19<1:29:53, 66.58s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 286/366 [8:03:55<1:40:51, 75.64s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 287/366 [8:04:56<1:33:39, 71.14s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 288/366 [8:10:09<3:06:53, 143.76s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 289/366 [8:11:06<2:31:09, 117.79s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 290/366 [8:12:36<2:18:38, 109.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 291/366 [8:13:32<1:56:29, 93.20s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 292/366 [8:14:18<1:37:25, 78.99s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 293/366 [8:15:40<1:37:20, 80.00s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 294/366 [8:16:25<1:23:23, 69.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 295/366 [8:18:00<1:31:14, 77.11s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 296/366 [8:18:52<1:21:14, 69.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 297/366 [8:19:50<1:16:08, 66.21s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 298/366 [8:20:23<1:03:31, 56.05s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 299/366 [8:22:46<1:31:53, 82.29s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 300/366 [8:26:16<2:12:40, 120.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 301/366 [8:27:22<1:52:47, 104.12s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 302/366 [8:28:17<1:35:22, 89.42s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 303/366 [8:33:40<2:47:32, 159.57s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 304/366 [8:35:17<2:25:23, 140.70s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 305/366 [8:36:49<2:08:19, 126.22s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 306/366 [8:38:05<1:51:11, 111.19s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 307/366 [8:38:55<1:31:17, 92.84s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 308/366 [8:39:26<1:11:37, 74.10s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 309/366 [8:40:21<1:04:59, 68.42s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 310/366 [8:47:05<2:37:59, 169.28s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 311/366 [8:47:45<1:59:34, 130.44s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/366 [8:48:45<1:38:13, 109.14s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/366 [8:51:36<1:52:54, 127.83s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 314/366 [8:56:07<2:27:53, 170.64s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/366 [8:56:41<1:50:09, 129.59s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/366 [8:59:09<1:52:35, 135.11s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/366 [9:05:27<2:50:01, 208.19s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 318/366 [9:06:22<2:09:47, 162.24s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/366 [9:15:02<3:31:01, 269.40s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/366 [9:22:43<4:10:36, 326.88s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 321/366 [9:23:37<3:03:47, 245.07s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 322/366 [9:27:58<3:03:12, 249.83s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 323/366 [9:34:40<3:31:45, 295.48s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 324/366 [9:35:24<2:34:06, 220.15s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 325/366 [9:37:12<2:07:28, 186.55s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 326/366 [9:37:40<1:32:40, 139.01s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 327/366 [9:38:14<1:09:42, 107.26s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 328/366 [9:39:37<1:03:23, 100.09s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 329/366 [9:40:31<53:17, 86.43s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 330/366 [9:41:32<47:10, 78.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 331/366 [9:43:19<50:50, 87.15s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 332/366 [9:45:07<52:55, 93.39s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 333/366 [9:45:56<44:03, 80.10s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 334/366 [9:46:14<32:42, 61.33s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 335/366 [9:46:41<26:28, 51.23s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 336/366 [9:49:17<41:20, 82.68s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 337/366 [9:50:13<36:02, 74.58s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 338/366 [9:52:02<39:39, 84.99s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 339/366 [9:53:13<36:19, 80.73s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 340/366 [9:57:56<1:01:20, 141.54s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 341/366 [9:58:32<45:41, 109.65s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 342/366 [9:59:43<39:18, 98.25s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 343/366 [10:01:24<37:54, 98.87s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 344/366 [10:02:12<30:39, 83.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 345/366 [10:03:03<25:53, 73.97s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 346/366 [10:03:37<20:36, 61.81s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 347/366 [10:04:44<20:08, 63.59s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 348/366 [10:07:24<27:45, 92.53s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 349/366 [10:08:32<24:08, 85.18s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 350/366 [10:09:20<19:42, 73.94s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 351/366 [10:10:46<19:20, 77.40s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 352/366 [10:11:16<14:45, 63.28s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 353/366 [10:14:24<21:49, 100.71s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 354/366 [10:17:45<26:08, 130.67s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 355/366 [10:19:04<21:08, 115.30s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 356/366 [10:19:41<15:17, 91.76s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 357/366 [10:27:08<29:44, 198.25s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 358/366 [10:31:04<27:57, 209.73s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 359/366 [10:32:00<19:05, 163.65s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 360/366 [10:33:03<13:20, 133.45s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 361/366 [10:34:16<09:35, 115.18s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 362/366 [10:34:55<06:09, 92.32s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 363/366 [10:35:32<03:47, 75.68s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 364/366 [10:36:18<02:13, 66.97s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 365/366 [10:38:41<01:29, 89.65s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 366/366 [10:40:18<00:00, 91.98s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 366/366 [10:40:18<00:00, 104.97s/it]
It's done
  0%|                                          | 0/31 [00:00<?, ?it/s]  3%|â–ˆ                                 | 1/31 [00:13<06:53, 13.78s/it]  3%|â–ˆ                                 | 1/31 [00:21<10:34, 21.14s/it]
It's done
  0%|                                          | 0/31 [00:00<?, ?it/s]  3%|â–ˆ                                 | 1/31 [00:09<04:45,  9.52s/it]  6%|â–ˆâ–ˆâ–                               | 2/31 [00:13<03:07,  6.46s/it] 10%|â–ˆâ–ˆâ–ˆâ–Ž                              | 3/31 [02:10<26:34, 56.93s/it] 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                             | 4/31 [02:35<19:50, 44.09s/it] 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 5/31 [02:50<14:32, 33.56s/it] 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/31 [02:56<10:08, 24.34s/it] 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 7/31 [03:41<12:22, 30.93s/it] 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 8/31 [06:20<27:31, 71.78s/it] 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 9/31 [06:44<20:50, 56.85s/it] 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 10/31 [07:10<16:33, 47.32s/it] 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 11/31 [07:55<15:33, 46.69s/it] 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 12/31 [08:13<12:01, 37.95s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 13/31 [08:28<09:18, 31.05s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 14/31 [08:47<07:43, 27.24s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 15/31 [08:56<05:47, 21.72s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 16/31 [10:17<09:53, 39.59s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 17/31 [10:24<06:57, 29.84s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 18/31 [10:48<06:03, 27.99s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 19/31 [12:24<09:44, 48.71s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 20/31 [12:59<08:10, 44.56s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 21/31 [14:15<08:59, 53.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 22/31 [15:35<09:15, 61.69s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 23/31 [15:59<06:42, 50.26s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 24/31 [16:06<04:22, 37.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 25/31 [16:12<02:48, 28.07s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26/31 [16:33<02:08, 25.74s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/31 [16:52<01:35, 23.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 28/31 [17:34<01:27, 29.25s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 29/31 [17:49<00:49, 24.96s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 30/31 [18:58<00:38, 38.18s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [19:19<00:00, 33.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [19:19<00:00, 37.41s/it]
It's done

Modle's Params: 3.189M
Traceback (most recent call last):
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 90, in <module>
    dataset_1 = Dataset(base_dir=base_dir, split='train', domain_list=train_domain_list_1, 
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/datasets/dataset.py", line 21, in __init__
    in os.listdir(os.path.join(self.base_dir, self.split, self.domain_list))]
FileNotFoundError: [Errno 2] No such file or directory: './data/brats/npz_data/train/KiTS_ss'

Modle's Params: 3.189M
  0%|                                                                                                                          | 0/62 [00:00<?, ?it/s]
  0%|                                                                                                                        | 0/1609 [00:00<?, ?it/s][AEpoch: 0, LR: 0.001
/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
Traceback (most recent call last):
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 140, in <module>
    outputs_soft = model(sample_data, domain_label=train_idx*torch.ones(sample_data.shape[0], dtype=torch.long))
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 186, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 201, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 108, in parallel_apply
    output.reraise()
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/_utils.py", line 706, in reraise
    raise exception
torch.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 83, in _worker
    output = module(*input, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/model/unetdsbn.py", line 177, in forward
    x2 = self.convd2(x1, domain_label=domain_label)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/model/unetdsbn.py", line 69, in forward
    y = conv2d(x, weight_2, bias_2)
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/model/layers.py", line 47, in conv2d
    return F.conv2d(inputs, weight, bias, stride, padding, dilation, groups)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 441.88 MiB is free. Process 65388 has 7.51 GiB memory in use. Process 4095 has 7.61 GiB memory in use. Process 1064370 has 6.76 GiB memory in use. Process 1071245 has 6.76 GiB memory in use. Process 2613261 has 2.86 GiB memory in use. Process 2614020 has 2.75 GiB memory in use. Process 2636940 has 2.83 GiB memory in use. Including non-PyTorch memory, this process has 10.00 GiB memory in use. Of the allocated memory 8.39 GiB is allocated by PyTorch, and 13.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

  0%|                                                                                                                          | 0/62 [00:56<?, ?it/s]
  0%|                                                                                                                        | 0/1609 [00:56<?, ?it/s]

Modle's Params: 3.189M
Epoch: 0, LR: 0.001
/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
Traceback (most recent call last):
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 140, in <module>
    outputs_soft = model(sample_data, domain_label=train_idx*torch.ones(sample_data.shape[0], dtype=torch.long))
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 186, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 201, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 108, in parallel_apply
    output.reraise()
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/_utils.py", line 706, in reraise
    raise exception
torch.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 83, in _worker
    output = module(*input, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/model/unetdsbn.py", line 177, in forward
    x2 = self.convd2(x1, domain_label=domain_label)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/model/unetdsbn.py", line 69, in forward
    y = conv2d(x, weight_2, bias_2)
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/model/layers.py", line 47, in conv2d
    return F.conv2d(inputs, weight, bias, stride, padding, dilation, groups)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 449.88 MiB is free. Process 65388 has 7.51 GiB memory in use. Process 4095 has 7.61 GiB memory in use. Process 1064370 has 6.76 GiB memory in use. Process 1071245 has 6.76 GiB memory in use. Process 2613261 has 2.86 GiB memory in use. Process 2614020 has 2.75 GiB memory in use. Process 2636940 has 2.83 GiB memory in use. Including non-PyTorch memory, this process has 10.00 GiB memory in use. Of the allocated memory 8.39 GiB is allocated by PyTorch, and 13.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Training started!

Modle's Params: 3.189M
Epoch: 1, LR: 0.001
Traceback (most recent call last):
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 131, in <module>
    print("train batch shape:", batch.shape)
AttributeError: 'dict' object has no attribute 'shape'
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 141
    print("shapes of input batch and masks"sample_data.shape, sample_label.shape)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
Training started!

Modle's Params: 3.189M
Epoch: 1, LR: 0.001
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
Traceback (most recent call last):
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 133, in <module>
    other_sample_batches = [next(data_iter[i]) for i in range(1, 2)]
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 133, in <listcomp>
    other_sample_batches = [next(data_iter[i]) for i in range(1, 2)]
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 42, in repeat_dataloader
    for x in iterable:
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1324, in _next_data
    return self._process_data(data)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
    data.reraise()
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/_utils.py", line 706, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 4.
Original Traceback (most recent call last):
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 155, in collate
    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 155, in <dictcomp>
    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
RuntimeError: stack expects each tensor to be equal size, but got [1, 512, 512] at entry 0 and [1, 512, 632] at entry 7

Training started!

Modle's Params: 3.189M
Epoch: 1, LR: 0.001
Traceback (most recent call last):
  File "/home/nagacharan/DNKiTS_baseline/Dual-Normalization/train_dn_unet.py", line 130, in <module>
    for i, batch in enumerate(dataloader_train[0]):
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
    return self._process_data(data)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
    data.reraise()
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/_utils.py", line 706, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 155, in collate
    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 155, in <dictcomp>
    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
  File "/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
RuntimeError: stack expects each tensor to be equal size, but got [1, 512, 512] at entry 0 and [1, 512, 796] at entry 14

Training started!

Modle's Params: 3.189M
Epoch: 1, LR: 0.001
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
/home/nagacharan/anaconda3/envs/kenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
number of batches: 142
epoch-1 - Average Loss: 0.16102548300380437
val batch length: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) (16, 512, 512)
output shape: torch.Size([16, 2, 512, 512])
prediction shape: (16, 2, 512, 512)
argmax prediction shape: (16, 512, 512)
val batch length: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) (16, 512, 512)
output shape: torch.Size([16, 2, 512, 512])
prediction shape: (16, 2, 512, 512)
argmax prediction shape: (16, 512, 512)
val batch length: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) (16, 512, 512)
output shape: torch.Size([16, 2, 512, 512])
prediction shape: (16, 2, 512, 512)
argmax prediction shape: (16, 512, 512)
val batch length: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) (16, 512, 512)
output shape: torch.Size([16, 2, 512, 512])
prediction shape: (16, 2, 512, 512)
argmax prediction shape: (16, 512, 512)
val batch length: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) (16, 512, 512)
output shape: torch.Size([16, 2, 512, 512])
prediction shape: (16, 2, 512, 512)
argmax prediction shape: (16, 512, 512)
val batch length: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) (16, 512, 512)
output shape: torch.Size([16, 2, 512, 512])
prediction shape: (16, 2, 512, 512)
argmax prediction shape: (16, 512, 512)
val batch length: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) (16, 512, 512)
output shape: torch.Size([16, 2, 512, 512])
prediction shape: (16, 2, 512, 512)
argmax prediction shape: (16, 512, 512)
val batch length: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) (16, 512, 512)
output shape: torch.Size([16, 2, 512, 512])
prediction shape: (16, 2, 512, 512)
argmax prediction shape: (16, 512, 512)
val batch length: 3
shapes of input batch and masks: torch.Size([7, 1, 512, 512]) (7, 512, 512)
output shape: torch.Size([7, 2, 512, 512])
prediction shape: (7, 2, 512, 512)
argmax prediction shape: (7, 512, 512)
Mean Dice: 0.25, HD: 147.63, ASD: 57.88
Saved new best model at epoch 1 with dice 0.2500
Epoch duration: 65.03 seconds
Epoch: 2, LR: 0.00099
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
train batch len: 3
shapes of input batch and masks: torch.Size([16, 1, 512, 512]) torch.Size([16, 2, 512, 512])
